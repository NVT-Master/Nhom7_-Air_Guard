# ğŸŒ¬ï¸ AIR GUARD â€“ PM2.5 Forecasting & AQI Alerts using Semi-Supervised Learning

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-orange.svg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE.txt)

> **Mini Project - Data Mining Course**  
> á»¨ng dá»¥ng Semi-Supervised Learning (Self-Training & Co-Training) Ä‘á»ƒ dá»± bÃ¡o cháº¥t lÆ°á»£ng khÃ´ng khÃ­ vÃ  cáº£nh bÃ¡o AQI.
- NhÃ³m 7:
- Báº¿ Quang Háº£i - MSV: 1771040011
- Nguyá»…n VÄƒn Tiáº¿n - MSV: 1771040025
- Nguyá»…n Duy Thuáº­n - MSV: 1771040024

---

## ğŸ“‹ Má»¥c lá»¥c

- [Giá»›i thiá»‡u](#-giá»›i-thiá»‡u)
- [Dataset](#-dataset)
- [Cáº¥u trÃºc dá»± Ã¡n](#-cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ i Ä‘áº·t](#ï¸-cÃ i-Ä‘áº·t)
- [HÆ°á»›ng dáº«n sá»­ dá»¥ng](#-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [PhÆ°Æ¡ng phÃ¡p](#-phÆ°Æ¡ng-phÃ¡p)
- [Káº¿t quáº£](#-káº¿t-quáº£)
- [TÃ i liá»‡u tham kháº£o](#-tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ¯ Giá»›i thiá»‡u

### Bá»‘i cáº£nh

Ã” nhiá»…m khÃ´ng khÃ­, Ä‘áº·c biá»‡t lÃ  bá»¥i má»‹n PM2.5, lÃ  váº¥n Ä‘á» mÃ´i trÆ°á»ng nghiÃªm trá»ng. Dá»± Ã¡n xÃ¢y dá»±ng há»‡ thá»‘ng:

1. **Dá»± bÃ¡o PM2.5** (regression + ARIMA)
2. **PhÃ¢n lá»›p AQI** Ä‘á»ƒ cáº£nh bÃ¡o theo tráº¡m
3. **Semi-Supervised Learning** khi thiáº¿u nhÃ£n AQI

### Táº¡i sao Semi-Supervised Learning?

| ThÃ¡ch thá»©c | Giáº£i phÃ¡p |
|------------|-----------|
| Dá»¯ liá»‡u cÃ³ nhÃ£n khan hiáº¿m | Táº­n dá»¥ng 95% dá»¯ liá»‡u khÃ´ng nhÃ£n |
| Gáº¯n nhÃ£n thá»§ cÃ´ng tá»‘n kÃ©m | Pseudo-labeling tá»± Ä‘á»™ng |
| Class imbalance | Self-Training & Co-Training |

### Thiáº¿t káº¿

- **OOP**: ThÆ° viá»‡n trong `src/`
- **Notebook-per-task**: Má»—i notebook lÃ m 1 nhiá»‡m vá»¥
- **Tutorial Notebooks**: HÆ°á»›ng dáº«n chi tiáº¿t tá»«ng bÆ°á»›c

---

## ğŸ“Š Dataset

### Beijing Multi-Site Air Quality Dataset

| ThÃ´ng tin | Chi tiáº¿t |
|-----------|----------|
| **Nguá»“n** | [UCI ML Repository](https://archive.ics.uci.edu/dataset/501) |
| **Thá»i gian** | 01/03/2013 â€“ 28/02/2017 |
| **Tráº¡m** | 12 tráº¡m táº¡i Báº¯c Kinh |
| **Táº§n suáº¥t** | HÃ ng giá» (~420,000 records) |

### CÃ¡c biáº¿n chÃ­nh

| Biáº¿n | MÃ´ táº£ | ÄÆ¡n vá»‹ |
|------|-------|--------|
| PM2.5 | Ná»“ng Ä‘á»™ bá»¥i má»‹n | Î¼g/mÂ³ |
| PM10, SO2, NO2, CO, O3 | Cháº¥t Ã´ nhiá»…m khÃ¡c | Î¼g/mÂ³ |
| TEMP, PRES, DEWP | Nhiá»‡t Ä‘á»™, Ã¡p suáº¥t, Ä‘iá»ƒm sÆ°Æ¡ng | Â°C, hPa |
| RAIN, WSPM | LÆ°á»£ng mÆ°a, tá»‘c Ä‘á»™ giÃ³ | mm, m/s |

### AQI Classes (6 má»©c)

| Class | PM2.5 24h (Î¼g/mÂ³) | Má»©c Ä‘á»™ |
|-------|-------------------|--------|
| ğŸŸ¢ Good | 0 - 12 | Tá»‘t |
| ğŸŸ¡ Moderate | 12.1 - 35.4 | Trung bÃ¬nh |
| ğŸŸ  Unhealthy_Sensitive | 35.5 - 55.4 | KhÃ´ng tá»‘t cho nhÃ³m nháº¡y cáº£m |
| ğŸ”´ Unhealthy | 55.5 - 150.4 | KhÃ´ng tá»‘t |
| ğŸŸ£ Very_Unhealthy | 150.5 - 250.4 | Ráº¥t khÃ´ng tá»‘t |
| ğŸŸ¤ Hazardous | > 250.4 | Nguy hiá»ƒm |

### CÃ¡ch náº¡p dá»¯ liá»‡u

```python
# CÃ¡ch 1: DÃ¹ng file ZIP local (khuyáº¿n nghá»‹)
USE_UCIMLREPO = False
RAW_ZIP_PATH = "data/raw/PRSA2017_Data_20130301-20170228.zip"

# CÃ¡ch 2: Táº£i tá»« UCI
USE_UCIMLREPO = True
```

> âš ï¸ **LÆ°u Ã½ leakage**: KhÃ´ng dÃ¹ng `PM2.5` / `pm25_24h` lÃ m feature cho mÃ´ hÃ¬nh phÃ¢n lá»›p AQI.

---

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
air_guard/
â”œâ”€â”€ ğŸ“„ README.md                    # File nÃ y
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencies
â”œâ”€â”€ ğŸ“„ LICENSE.txt                  # MIT License
â”œâ”€â”€ ğŸ“„ run_papermill.py             # Cháº¡y pipeline tá»± Ä‘á»™ng
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ raw/                        # ZIP dá»¯ liá»‡u gá»‘c
â”‚   â””â”€â”€ processed/                  # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”‚       â””â”€â”€ dataset_semi_supervised.parquet
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/
â”‚   â”‚
â”‚   â”‚   # === TUTORIAL NOTEBOOKS (Khuyáº¿n nghá»‹ cho sinh viÃªn) ===
â”‚   â”œâ”€â”€ ğŸ““ air_guard_tutorial.ipynb          # Pháº§n 1-5: EDA â†’ Baseline
â”‚   â”œâ”€â”€ ğŸ““ air_guard_semi_supervised.ipynb   # Pháº§n 6-9: Semi-Supervised
â”‚   â”‚
â”‚   â”‚   # === PIPELINE NOTEBOOKS ===
â”‚   â”œâ”€â”€ preprocessing_and_eda.ipynb
â”‚   â”œâ”€â”€ feature_preparation.ipynb
â”‚   â”œâ”€â”€ classification_modelling.ipynb
â”‚   â”œâ”€â”€ regression_modelling.ipynb
â”‚   â”œâ”€â”€ arima_forecasting.ipynb
â”‚   â”œâ”€â”€ semi_dataset_preparation.ipynb
â”‚   â”œâ”€â”€ semi_self_training.ipynb
â”‚   â”œâ”€â”€ semi_co_training.ipynb
â”‚   â”œâ”€â”€ semi_supervised_report.ipynb
â”‚   â””â”€â”€ runs/                        # Output tá»« Papermill
â”‚
â””â”€â”€ ğŸ“‚ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ classification_library.py    # HÃ m cho classification
    â”œâ”€â”€ regression_library.py        # HÃ m cho regression
    â”œâ”€â”€ semi_supervised_library.py   # Self-Training, Co-Training
    â””â”€â”€ timeseries_library.py        # Xá»­ lÃ½ chuá»—i thá»i gian
```

---

## âš™ï¸ CÃ i Ä‘áº·t

### YÃªu cáº§u
- Python 3.10+
- 8GB RAM (khuyáº¿n nghá»‹ 16GB)

### CÃ i Ä‘áº·t

```bash
# Clone repository
git clone https://github.com/your-username/air_guard.git
cd air_guard

# Táº¡o mÃ´i trÆ°á»ng Conda
conda create -n beijing_env python=3.11 -y
conda activate beijing_env

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt

# ÄÄƒng kÃ½ kernel cho Jupyter
python -m ipykernel install --user --name beijing_env --display-name "beijing_env"
```

### Kiá»ƒm tra
```bash
python -c "import pandas, sklearn, numpy; print('OK')"
```

---

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### ğŸ“ CÃ¡ch 1: Tutorial Notebooks (Khuyáº¿n nghá»‹)

**BÆ°á»›c 1**: Cháº¡y Tutorial Part 1

```bash
jupyter notebook notebooks/air_guard_tutorial.ipynb
```

Ná»™i dung:
- âœ… **Pháº§n 1**: Load vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u
- âœ… **Pháº§n 2**: PhÃ¢n tÃ­ch Missing Values
- âœ… **Pháº§n 3**: Gáº¯n nhÃ£n AQI, chia Labeled/Unlabeled (5%/95%)
- âœ… **Pháº§n 4**: Feature Engineering (Lag, Rolling, Time)
- âœ… **Pháº§n 5**: Supervised Baseline

**BÆ°á»›c 2**: Cháº¡y Tutorial Part 2

```bash
jupyter notebook notebooks/air_guard_semi_supervised.ipynb
```

Ná»™i dung:
- âœ… **Pháº§n 6**: Self-Training (Pseudo-labeling)
- âœ… **Pháº§n 7**: Co-Training (Two-view learning)
- âœ… **Pháº§n 8**: Thá»­ nghiá»‡m tham sá»‘ (Ï„ = 0.8, 0.9)
- âœ… **Pháº§n 9**: Tá»•ng káº¿t vÃ  so sÃ¡nh

### âš¡ CÃ¡ch 2: Pipeline tá»± Ä‘á»™ng (Papermill)

```bash
python run_papermill.py
```

Output:
- Notebooks: `notebooks/runs/*_run.ipynb`
- Artifacts: `data/processed/`

---

## ğŸ”¬ PhÆ°Æ¡ng phÃ¡p

### Pipeline tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     AIR GUARD Pipeline                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Data Loading        â†’ Táº£i tá»« UCI Repository                 â”‚
â”‚  2. EDA                 â†’ KhÃ¡m phÃ¡, phÃ¢n tÃ­ch missing           â”‚
â”‚  3. AQI Labeling        â†’ Gáº¯n nhÃ£n 6 má»©c tá»« PM2.5 24h           â”‚
â”‚  4. Train/Test Split    â†’ Theo thá»i gian (2017 = test)          â”‚
â”‚  5. Labeled/Unlabeled   â†’ 5% labeled, 95% unlabeled             â”‚
â”‚  6. Feature Engineering â†’ Lag, Rolling, Time features           â”‚
â”‚  7. Supervised Baseline â†’ HistGradientBoosting (5% data)        â”‚
â”‚  8. Self-Training       â†’ Pseudo-labeling iterative             â”‚
â”‚  9. Co-Training         â†’ Two-view collaborative learning       â”‚
â”‚ 10. Evaluation          â†’ Compare all methods                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1ï¸âƒ£ Self-Training

```
Algorithm Self-Training:
    Input: L (labeled), U (unlabeled), Ï„ (threshold)
    
    1. Train model M on L
    2. Repeat until convergence:
        a. Predict probabilities for U
        b. Select samples with confidence >= Ï„
        c. Add pseudo-labeled samples to L
        d. Retrain M
    3. Return: Improved model M
```

**Tham sá»‘**: `Ï„ âˆˆ {0.85, 0.90, 0.95}`, `max_iter = 10`

### 2ï¸âƒ£ Co-Training

```
Algorithm Co-Training:
    Input: L, U, View1 (temporal), View2 (environmental)
    
    1. Train M1 on L[View1], M2 on L[View2]
    2. Repeat:
        a. M1 predicts â†’ confident samples
        b. M2 predicts â†’ confident samples
        c. Exchange pseudo-labels (consensus)
        d. Retrain both
    3. Return: Ensemble M1 + M2
```

**Chia View**:
- **View 1 (Temporal)**: hour, day, month, lag features
- **View 2 (Environmental)**: TEMP, PRES, WSPM, rolling features

---

## ğŸ“ˆ Káº¿t quáº£

### So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p

| PhÆ°Æ¡ng phÃ¡p | Accuracy | F1 Macro | F1 Weighted |
|-------------|----------|----------|-------------|
| Supervised Baseline (5% data) | ~0.65 | ~0.40 | ~0.63 |
| Self-Training (Ï„=0.9) | ~0.67 | ~0.42 | ~0.65 |
| Self-Training (Ï„=0.8) | ~0.66 | ~0.41 | ~0.64 |
| Co-Training | ~0.68 | ~0.43 | ~0.66 |

> **LÆ°u Ã½**: Káº¿t quáº£ thay Ä‘á»•i tÃ¹y random seed.

### ğŸ’¡ Insights chÃ­nh

1. **Semi-supervised cáº£i thiá»‡n** ~2-5% khi chá»‰ cÃ³ 5% labeled data
2. **Threshold Ï„ quan trá»ng**: Ï„ cao â†’ pseudo-label cháº¥t lÆ°á»£ng hÆ¡n
3. **Co-Training hiá»‡u quáº£** khi hai view Ä‘á»™c láº­p
4. **Class imbalance** váº«n lÃ  thÃ¡ch thá»©c (lá»›p Hazardous khÃ³ dá»± Ä‘oÃ¡n)

---

## ğŸ“š ThÆ° viá»‡n OOP (src/)

### `classification_library.py`
- `time_split(df, cutoff)`: Chia train/test theo thá»i gian
- `train_classifier(...)`: Train vÃ  evaluate model
- `AQI_CLASSES`: Danh sÃ¡ch 6 má»©c AQI

### `semi_supervised_library.py`
- `SelfTrainingAQIClassifier`: Self-training vá»›i pseudo-labeling
- `CoTrainingAQIClassifier`: Co-training vá»›i 2 views
- `mask_labels_time_aware(...)`: Giáº£ láº­p thiáº¿u nhÃ£n
- `add_alert_columns(...)`: Táº¡o cá»™t cáº£nh bÃ¡o

---

## ğŸ“ TÃ i liá»‡u tham kháº£o

### Papers
1. Yarowsky, D. (1995). *Unsupervised Word Sense Disambiguation*
2. Blum & Mitchell (1998). *Combining Labeled and Unlabeled Data with Co-Training*

### Dataset
- Zhang, S., et al. (2017). *Cautionary Tales on Air-Quality Improvement in Beijing*
- [UCI ML Repository - Beijing Air Quality](https://archive.ics.uci.edu/dataset/501)

---

## ğŸ‘¤ TÃ¡c giáº£

- **Sinh viÃªn**: NhÃ³m 7
- **MÃ´n há»c**: Data Mining
- **Há»c ká»³**: HK2 - NÄƒm 3

---

## ğŸ“„ License

MIT â€” Sá»­ dá»¥ng tá»± do cho nghiÃªn cá»©u, há»c thuáº­t vÃ  á»©ng dá»¥ng ná»™i bá»™.

---

<p align="center">
  <b>â­ Náº¿u dá»± Ã¡n há»¯u Ã­ch, hÃ£y cho má»™t star! â­</b>
</p>
